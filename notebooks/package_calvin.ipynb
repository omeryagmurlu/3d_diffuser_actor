{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"Debugging...\")\n",
    "def custom_repr(self):\n",
    "    return f'{{Tensor:{tuple(self.shape)}}}'\n",
    "    # return f'{{Tensor:{tuple(self.shape)}}} {original_repr(self)}'\n",
    "\n",
    "original_repr = torch.Tensor.__repr__\n",
    "torch.Tensor.__repr__ = custom_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tap\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import blosc\n",
    "from PIL import Image\n",
    "import einops\n",
    "\n",
    "from calvin_env.envs.play_table_env import get_env\n",
    "from utils.utils_with_calvin import (\n",
    "    keypoint_discovery,\n",
    "    deproject,\n",
    "    get_gripper_camera_view_matrix,\n",
    "    convert_rotation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def write_video_from_array(array, output_file, fps=30):\n",
    "    \"\"\"\n",
    "    Writes a NumPy array of shape (n_frames, h, w, c) to a video file.\n",
    "\n",
    "    Parameters:\n",
    "    - array: NumPy array of shape (n_frames, h, w, c), where c is the number of color channels (3 for RGB/BGR).\n",
    "    - output_file: The path of the output video file (e.g., 'output_video.mp4').\n",
    "    - fps: Frames per second of the output video (default is 30).\n",
    "    \"\"\"\n",
    "    # Get the shape of the input array\n",
    "    n_frames, h, w, c = array.shape\n",
    "\n",
    "    # Ensure the array has 3 color channels (RGB or BGR)\n",
    "    if c != 3:\n",
    "        raise ValueError(\"Array must have 3 color channels (RGB/BGR).\")\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (w, h))\n",
    "\n",
    "    # Write each frame to the video\n",
    "    for i in range(n_frames):\n",
    "        frame = array[i]\n",
    "        # Write the frame\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "    print(f\"Video saved as {output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "# array = np.random.randint(0, 256, (100, 480, 640, 3), dtype=np.uint8)\n",
    "# write_video_from_array(array, 'output_video.mp4', fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"training\"\n",
    "root_dir = Path(\"../calvin/dataset/calvin_debug_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/9, start_id:358656, end_id:358720, len:65\n",
      "Video saved as ep_0.mp4\n"
     ]
    }
   ],
   "source": [
    "annotations = np.load(\n",
    "    f'{root_dir}/{split}/lang_annotations/auto_lang_ann.npy',\n",
    "    allow_pickle=True\n",
    ").item()\n",
    "\n",
    "len_anno = len(annotations['info']['indx'])\n",
    "for anno_ind, (start_id, end_id) in enumerate(annotations['info']['indx']):\n",
    "    print(f'Processing {anno_ind}/{len_anno}, start_id:{start_id}, end_id:{end_id}, len:{end_id-start_id+1}')\n",
    "\n",
    "    ep_imgs = []\n",
    "    for ep_id in range(start_id, end_id + 1):\n",
    "        episode = 'episode_{:07d}.npz'.format(ep_id)\n",
    "        data = np.load(f'{root_dir}/{split}/{episode}')\n",
    "        rgb_static = data['rgb_static']\n",
    "        ep_imgs.append(rgb_static)\n",
    "\n",
    "    ep_imgs = np.stack(ep_imgs, axis=0)\n",
    "    ep_img = einops.rearrange(ep_imgs, 'b h w c -> (b h) w c')\n",
    "\n",
    "    write_video_from_array(ep_imgs, f'anno_{anno_ind}.mp4', fps=30)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f'{root_dir}/{split}/{episode}')\n",
    "\n",
    "rgb_static = data['rgb_static']  # (200, 200, 3)\n",
    "rgb_gripper = data['rgb_gripper']  # (84, 84, 3)\n",
    "depth_static = data['depth_static']  # (200, 200)\n",
    "depth_gripper = data['depth_gripper']  # (84, 84)\n",
    "\n",
    "# data['robot_obs'] is (15,), data['scene_obs'] is (24,)\n",
    "env.reset(robot_obs=data['robot_obs'], scene_obs=data['scene_obs'])\n",
    "static_cam = env.cameras[0]\n",
    "gripper_cam = env.cameras[1]\n",
    "gripper_cam.viewMatrix = get_gripper_camera_view_matrix(gripper_cam)\n",
    "\n",
    "static_pcd = deproject(\n",
    "    static_cam, depth_static,\n",
    "    homogeneous=False, sanity_check=False\n",
    ").transpose(1, 0)\n",
    "static_pcd = np.reshape(\n",
    "    static_pcd, (depth_static.shape[0], depth_static.shape[1], 3)\n",
    ")\n",
    "gripper_pcd = deproject(\n",
    "    gripper_cam, depth_gripper,\n",
    "    homogeneous=False, sanity_check=False\n",
    ").transpose(1, 0)\n",
    "gripper_pcd = np.reshape(\n",
    "    gripper_pcd, (depth_gripper.shape[0], depth_gripper.shape[1], 3)\n",
    ")\n",
    "\n",
    "# map RGB to [-1, 1]\n",
    "rgb_static = rgb_static / 255. * 2 - 1\n",
    "rgb_gripper = rgb_gripper / 255. * 2 - 1\n",
    "\n",
    "# Map gripper openess to [0, 1]\n",
    "proprio = np.concatenate([\n",
    "    data['robot_obs'][:3],\n",
    "    data['robot_obs'][3:6],\n",
    "    (data['robot_obs'][[-1]] > 0).astype(np.float32)\n",
    "], axis=-1)\n",
    "\n",
    "# Put them into a dict\n",
    "datas['static_pcd'].append(static_pcd)  # (200, 200, 3)\n",
    "datas['static_rgb'].append(rgb_static)  # (200, 200, 3)\n",
    "datas['gripper_pcd'].append(gripper_pcd)  # (84, 84, 3)\n",
    "datas['gripper_rgb'].append(rgb_gripper)  # (84, 84, 3)\n",
    "datas['proprios'].append(proprio)  # (8,)\n",
    "datas['annotation_id'].append(ann_id)  # int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
